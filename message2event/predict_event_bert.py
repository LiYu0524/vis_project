import pandas as pd
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

class PredictionDataset(Dataset):
    """
    ç”¨äºé¢„æµ‹çš„æ•°æ®é›†ç±»
    """
    def __init__(self, texts, tokenizer, max_length=512):
        self.texts = texts
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        
        # ä½¿ç”¨BERT tokenizerè¿›è¡Œç¼–ç 
        encoding = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=self.max_length,
            return_token_type_ids=False,
            padding='max_length',
            truncation=True,
            return_attention_mask=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'text': text
        }

def predict_csv_events(csv_file_path, model_path, output_csv_path, batch_size=32):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹CSVæ–‡ä»¶ä¸­çš„æ¶ˆæ¯è¿›è¡Œäº‹ä»¶åˆ†ç±»é¢„æµ‹
    
    Args:
        csv_file_path: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
        model_path: è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        output_csv_path: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
        batch_size: æ‰¹å¤„ç†å¤§å°
    """
    
    # æ£€æŸ¥GPUå¯ç”¨æ€§
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    # è¯»å–CSVæ–‡ä»¶
    print("Loading CSV file...")
    df = pd.read_csv(csv_file_path)
    print(f"Loaded {len(df)} records")
    
    # æå–æ¶ˆæ¯æ–‡æœ¬
    messages = df['message'].fillna('').tolist()  # å¤„ç†å¯èƒ½çš„NaNå€¼
    
    # åŠ è½½æ¨¡å‹æƒé‡å’Œé…ç½®
    print("Loading model...")
    checkpoint = torch.load(model_path, map_location=device)
    
    # ä»checkpointä¸­è·å–æ ‡ç­¾æ˜ å°„
    if 'label_map' in checkpoint:
        label_map = checkpoint['label_map']
        id_to_label = {v: k for k, v in label_map.items()}
    else:
        # å¦‚æœcheckpointä¸­æ²¡æœ‰label_mapï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„
        label_map = {
            'power issues': 0,
            'water issues': 1, 
            'road issues': 2,
            'medical issues': 3,
            'building damage issues': 4,
            'Other complaints': 5
        }
        id_to_label = {v: k for k, v in label_map.items()}
    
    print(f"Label mapping: {label_map}")
    
    # åˆå§‹åŒ–tokenizerå’Œæ¨¡å‹
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    
    from transformers import BertForSequenceClassification
    model = BertForSequenceClassification.from_pretrained(
        'bert-base-uncased',
        num_labels=len(label_map),
        output_attentions=False,
        output_hidden_states=False
    )
    
    # åŠ è½½æ¨¡å‹æƒé‡
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    
    print("Model loaded successfully!")
    
    # åˆ›å»ºé¢„æµ‹æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
    prediction_dataset = PredictionDataset(messages, tokenizer)
    prediction_loader = DataLoader(
        prediction_dataset,
        batch_size=batch_size,
        shuffle=False,  # ä¿æŒé¡ºåº
        num_workers=4 if device.type == 'cuda' else 2
    )
    
    # è¿›è¡Œé¢„æµ‹
    print("Starting prediction...")
    predictions = []
    confidences = []
    
    with torch.no_grad():
        for batch in tqdm(prediction_loader, desc="Predicting"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            logits = outputs.logits
            
            # è®¡ç®—æ¦‚ç‡å’Œé¢„æµ‹
            probabilities = torch.nn.functional.softmax(logits, dim=1)
            batch_predictions = torch.argmax(logits, dim=1).cpu().numpy()
            batch_confidences = probabilities.max(dim=1)[0].cpu().numpy()
            
            # è½¬æ¢ä¸ºæ ‡ç­¾åç§°
            batch_labels = [id_to_label[pred] for pred in batch_predictions]
            
            predictions.extend(batch_labels)
            confidences.extend(batch_confidences)
    
    print(f"Prediction completed! Processed {len(predictions)} messages")
    
    # æ›´æ–°DataFrame
    df['event_type'] = predictions
    df['prediction_confidence'] = confidences  # æ·»åŠ ç½®ä¿¡åº¦åˆ—
    
    # æ˜¾ç¤ºé¢„æµ‹ç»Ÿè®¡
    print("\nPrediction statistics:")
    print(df['event_type'].value_counts())
    print(f"\nAverage confidence: {np.mean(confidences):.4f}")
    
    # ä¿å­˜ç»“æœ
    df.to_csv(output_csv_path, index=False)
    print(f"\nResults saved to: {output_csv_path}")
    
    # æ˜¾ç¤ºä¸€äº›ç¤ºä¾‹é¢„æµ‹
    print("\nSample predictions:")
    sample_df = df.sample(n=min(10, len(df)))
    for idx, row in sample_df.iterrows():
        print(f"Message: {row['message'][:100]}...")
        print(f"Predicted: {row['event_type']} (confidence: {row['prediction_confidence']:.4f})")
        print("-" * 50)
    
    return df

def batch_predict_with_analysis(csv_file_path, model_path, output_csv_path, batch_size=32):
    """
    å¸¦åˆ†æåŠŸèƒ½çš„æ‰¹é‡é¢„æµ‹å‡½æ•°
    """
    # æ‰§è¡Œé¢„æµ‹
    df = predict_csv_events(csv_file_path, model_path, output_csv_path, batch_size)
    
    # åˆ†æç»“æœ
    print("\n" + "="*60)
    print("PREDICTION ANALYSIS")
    print("="*60)
    
    # ç½®ä¿¡åº¦åˆ†æ
    confidence_stats = df['prediction_confidence'].describe()
    print(f"\nConfidence Statistics:")
    print(confidence_stats)
    
    # ä½ç½®ä¿¡åº¦é¢„æµ‹
    low_confidence_threshold = 0.5
    low_confidence_predictions = df[df['prediction_confidence'] < low_confidence_threshold]
    print(f"\nLow confidence predictions (< {low_confidence_threshold}): {len(low_confidence_predictions)}")
    
    if len(low_confidence_predictions) > 0:
        print("Sample low confidence predictions:")
        for idx, row in low_confidence_predictions.head(5).iterrows():
            print(f"Message: {row['message'][:80]}...")
            print(f"Predicted: {row['event_type']} (confidence: {row['prediction_confidence']:.4f})")
            print("-" * 40)
    
    # å„ç±»åˆ«çš„å¹³å‡ç½®ä¿¡åº¦
    print(f"\nAverage confidence by category:")
    category_confidence = df.groupby('event_type')['prediction_confidence'].agg(['mean', 'count'])
    print(category_confidence.round(4))
    
    return df

if __name__ == "__main__":
    # è®¾ç½®æ–‡ä»¶è·¯å¾„
    input_csv = 'output_with_event_type_reliability.csv'
    model_weights = 'best_event_classifier.pt'
    output_csv = 'predicted_events_output.csv'
    
    # æ‰§è¡Œé¢„æµ‹
    try:
        result_df = batch_predict_with_analysis(
            csv_file_path=input_csv,
            model_path=model_weights,
            output_csv_path=output_csv,
            batch_size=64  # å¯ä»¥æ ¹æ®GPUå†…å­˜è°ƒæ•´
        )
        
        print(f"\nâœ… Prediction completed successfully!")
        print(f"ğŸ“ Results saved to: {output_csv}")
        
    except Exception as e:
        print(f"âŒ Error during prediction: {str(e)}")
        import traceback
        traceback.print_exc()